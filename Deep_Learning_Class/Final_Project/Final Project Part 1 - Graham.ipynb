{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a02d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "from collections import Counter\n",
    "\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL \n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import glob\n",
    "from glob import glob\n",
    "\n",
    "from IPython.display import display\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a847fa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Download the dataset that is about 350 MB from Kaggle into the local disk and unzip it.\n",
    "import pathlib\n",
    "img_dir = 'C:/Users/srgra/OneDrive/Documents/Deep Learning/Homework/Final Data Part 1/indoorCVPR_09/Images'\n",
    "print(f'The indoorCVPR_09 photes are stored in local directory : {img_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86efbfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_files = 0\n",
    "for root, dirs, files in os.walk(str(img_dir)):\n",
    "    level = root.replace(str(img_dir), '').count(os.sep)\n",
    "    indent = ' ' * 4 * (level)\n",
    "    print(f'{indent}{os.path.basename(root)}/ ({len(files)} files)')\n",
    "    total_files += len(files)\n",
    "print(f'There are {total_files - 1} images in this dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d714737",
   "metadata": {},
   "outputs": [],
   "source": [
    "IndoorImage_dir = [ name for name in list(os.listdir(img_dir)) if os.path.isdir(os.path.join(img_dir, name)) ]\n",
    "print(f' The Indoor Image labels = {IndoorImage_dir}')\n",
    "\n",
    "IndoorImage_dir.sort()   \n",
    "print(f'\\n The SORTED Indoor Image labels = {IndoorImage_dir}')\n",
    "\n",
    "print(f'\\nThere are {len(IndoorImage_dir)} classes of Indoor Images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4d1354",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = glob(os.path.join(img_dir,'*/*.*'))\n",
    "\n",
    "bad_paths = []\n",
    "\n",
    "for image_path in img_paths:\n",
    "    try:\n",
    "        img_bytes = tf.io.read_file(image_path)\n",
    "        decoded_img = tf.io.decode_image(img_bytes)\n",
    "    except tf.errors.InvalidArgumentError as e:\n",
    "        print(f\"Found bad path {image_path}...{e}\")\n",
    "        bad_paths.append(image_path)\n",
    "        os.remove(image_path)\n",
    "\n",
    "print(\"BAD PATHS:\")\n",
    "for bad_path in bad_paths:\n",
    "    print(f\"{bad_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2794686",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 777\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "for i in range(len(IndoorImage_dir)):\n",
    "    image_file = glob(os.path.join(img_dir, IndoorImage_dir[i], '*'))\n",
    "    img = PIL.Image.open(str(image_file[0]))\n",
    "    \n",
    "    print(f'(Image size  = ({img.size[0]}, {img.size[1]}, {len(img.mode)}) ; IndoorsPlace = {IndoorImage_dir[i]})')\n",
    "    display(img)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445bb1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "image_height = 256\n",
    "image_width = 256\n",
    "split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0115a6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  img_dir,\n",
    "  labels='inferred',\n",
    "  label_mode='int',\n",
    "  validation_split= split,\n",
    "  subset=\"training\",\n",
    "  seed= 1001,\n",
    "  image_size=(image_height, image_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d8c297",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  img_dir,\n",
    "  labels='inferred',\n",
    "  label_mode='int',\n",
    "  validation_split= split,\n",
    "  subset=\"validation\",\n",
    "  seed=1001,\n",
    "  image_size=(image_height, image_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915b8a5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for img, lab in train_data.take(1):\n",
    "    print(img[1].numpy().astype(\"uint16\"))\n",
    "    print(f'minimum = {np.amin(img[0].numpy().astype(\"uint16\"))}, maximum = {np.amax(img[0].numpy().astype(\"uint16\"))}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8855d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for img, lab in train_data.take(1):\n",
    "    for i in range(16):\n",
    "        ax = plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(img[i].numpy().astype(\"uint16\"))\n",
    "        plt.title(IndoorImage_dir[lab[i]]) \n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691413f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_data:\n",
    "    print(f'image_batch.shape = {image_batch.shape} \\nlabels_batch.shape = {labels_batch.shape } ')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cc5ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_data = train_data.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_data = val_data.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feab3ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Build a baseline CNN model on the training dataset and evaluate it on the test dataset.\n",
    "model = Sequential([\n",
    "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(image_height, image_width, 3)),\n",
    "  layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(2,2),\n",
    "  layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "  layers.MaxPooling2D((2,2)),\n",
    "  layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "  layers.MaxPooling2D((2,2)),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.Dense(67)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41580bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca28d19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b095200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', patience = 3)  \n",
    "history = model.fit(train_data, validation_data = val_data, epochs = 5, callbacks = [callback], verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb94fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = pd.DataFrame(history.history)\n",
    "train_history['epoch'] = history.epoch\n",
    "\n",
    "sns.lineplot(x='epoch', y ='loss', data = train_history)\n",
    "sns.lineplot(x='epoch', y ='val_loss', data = train_history)\n",
    "plt.legend(labels=['train_loss', 'val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b970f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='epoch', y ='accuracy', data =train_history)\n",
    "sns.lineplot(x='epoch', y ='val_accuracy', data =train_history)\n",
    "plt.legend(labels=['train_accuracy', 'val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f748b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = model.predict(img)\n",
    "score = tf.nn.softmax(y_pred_prob)\n",
    "y_pred = np.argmax(score, axis = 1)\n",
    "print(classification_report (lab, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbaeb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Build a second CNN model with data augmentation and dropout and evaluate it on the test dataset.\n",
    "data_aug = tf.keras.Sequential([tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\", \n",
    "    input_shape=(image_height, image_width, 3)),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor=0.1, width_factor = 0.1),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomZoom(height_factor=(0.1, 0.1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fe49b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image, label, target_height = 256, target_width = 256):\n",
    "    image = tf.cast(image, tf.float32)/255.\n",
    "    image = tf.image.resize_with_crop_or_pad(image, target_height, target_width)\n",
    "    return image, label\n",
    "train_data_normalized = train_data.map(normalize_image, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for image, label in train_data_normalized.take(1):\n",
    "    for i in range(16):\n",
    "        aug_images = data_aug(image)\n",
    "        ax = plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(aug_images[0])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d25cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([data_aug,\n",
    "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(image_height, image_width, 3)),\n",
    "  layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(2,2),\n",
    "  layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "  layers.MaxPooling2D((2,2)),\n",
    "  layers.Dropout(0.25),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.Dropout(0.25),                  \n",
    "  layers.Dense(67)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5211aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17018c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d194a07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience= 3)\n",
    "history = model.fit(train_data, epochs=5, validation_data=(val_data), callbacks=[callback], verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b4eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = pd.DataFrame(history.history)\n",
    "train_history['epoch'] = history.epoch\n",
    "\n",
    "sns.lineplot(x='epoch', y ='loss', data = train_history)\n",
    "sns.lineplot(x='epoch', y ='val_loss', data = train_history)\n",
    "plt.legend(labels=['train_loss', 'val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65d1bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='epoch', y ='accuracy', data =train_history)\n",
    "sns.lineplot(x='epoch', y ='val_accuracy', data =train_history)\n",
    "plt.legend(labels=['train_accuracy', 'val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc39f153",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = model.predict(img)\n",
    "score = tf.nn.softmax(y_pred_prob)\n",
    "y_pred = np.argmax(score, axis = 1)\n",
    "print(classification_report (lab, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61e947e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Build a third CNN model based on the pre-trained model (transfer learning) and evaluate it on the test dataset.\n",
    "IMG_SHAPE = (image_height, image_width, 3)\n",
    "\n",
    "MobileNetV3Large_model = tf.keras.applications.MobileNetV3Large(input_shape = IMG_SHAPE, include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28303d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "MobileNetV3Large_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c780c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(MobileNetV3Large_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41abf8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "MobileNetV3Large_model.trainable = False\n",
    "\n",
    "preprocess_input = tf.keras.applications.mobilenet_v3.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d22d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(train_data))\n",
    "feature_batch = MobileNetV3Large_model(image_batch)\n",
    "print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a35a23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a7a4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Flatten_layer = tf.keras.layers.Flatten()\n",
    "feature_batch_average = Flatten_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a9fe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_layer = tf.keras.layers.Dense(67)\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(f' The size of the predicted value for a given batch = {prediction_batch.shape}')\n",
    "print(prediction_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab5a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape = IMG_SHAPE)\n",
    "\n",
    "x = data_aug(inputs)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "x = MobileNetV3Large_model(x, training=False)\n",
    "\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "outputs = prediction_layer(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e729c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51423e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe716808",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727ca95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience= 3)\n",
    "history = model.fit(train_data, epochs=5, validation_data=(val_data), callbacks=[callback], verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed29607",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = pd.DataFrame(history.history)\n",
    "train_history['epoch'] = history.epoch\n",
    "\n",
    "sns.lineplot(x='epoch', y ='loss', data = train_history)\n",
    "sns.lineplot(x='epoch', y ='val_loss', data = train_history)\n",
    "plt.legend(labels=['train_loss', 'val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aee0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='epoch', y ='accuracy', data =train_history)\n",
    "sns.lineplot(x='epoch', y ='val_accuracy', data =train_history)\n",
    "plt.legend(labels=['train_accuracy', 'val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a337ac59",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = model.predict(img)\n",
    "score = tf.nn.softmax(y_pred_prob)\n",
    "y_pred = np.argmax(score, axis = 1)\n",
    "print(classification_report (lab, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59f4981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 Which model do you recommend for the model in Q2, Q3, and Q4? Justify your answer.\n",
    "# I would recommend the model from Q2, as the accuracy was 0.94. The accuracy of Q3 was only 0.16 and the accuracy of Q4 was\n",
    "# only 0.59."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
